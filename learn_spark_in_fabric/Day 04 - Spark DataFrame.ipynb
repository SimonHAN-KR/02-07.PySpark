{"cells":[{"cell_type":"markdown","id":"62a3f978-6a05-4972-86b3-da995ba266ad","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["\n","\n","In this video: \n","- What is a Spark DataFrame? \n","- Creating our first DataFrame\n","- Schemas"]},{"cell_type":"markdown","id":"2e1af36d-4b97-4aaf-be9d-fa824a616620","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["## What is a Spark DataFrame? \n","\n","A Spark DataFrame is like a distributed, in-memory table with **named columns** and a **schema**. \n","\n","The schema defines the columns and the data types for each column. \n","\n","Inspired by Pandas DataFrames! "]},{"cell_type":"markdown","id":"e02d152e-d3f0-40da-a26c-187cb02b97e9","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["## Creating our first data frame (with a schema)\n"]},{"cell_type":"code","execution_count":null,"id":"c37cf578-19c7-4410-a6f1-ea3a5704b021","metadata":{},"outputs":[],"source":["from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n","\n","data2 = [(\"Jack\",\"\",\"Eldridge\",\"36636\",\"M\",90000),\n","    (\"Matthew\",\"J\", \"Munro\",\"28832\",\"M\",45400),\n","    (\"Sheila\",\"Oway\", \"Roberts\",\"12114\",\"F\",64000),\n","    (\"Anne\",\"\", \"Dushane\",\"32192\",\"F\",141000),\n","    (\"Jane\",\"Rebecca\",\"Jones\",\"99482\",\"F\",56000)\n","  ]\n","\n","schema = StructType([ \n","    StructField(\"firstname\",StringType(),True), \n","    StructField(\"middlename\",StringType(),True), \n","    StructField(\"lastname\",StringType(),True), \n","    StructField(\"id\", StringType(), True), \n","    StructField(\"gender\", StringType(), True), \n","    StructField(\"salary\", IntegerType(), True) \n","  ])\n"," \n","df = spark.createDataFrame(data=data2,schema=schema)\n","df.printSchema()\n","df.show(truncate=False)\n"]},{"cell_type":"code","execution_count":null,"id":"6db0cdce-be89-46d4-8972-0211aa013f34","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["type(df)"]},{"cell_type":"markdown","id":"68d827f1-5b40-4b59-b2c4-954832ff6614","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["## Why Schemas? \n","- Commonly used, especially with reading from an external data source (including files). \n","- Spark doesn't have to 'infer' the data type (which can be expensive). \n","- You can detect errors early if the data doesn't match the schema.  "]},{"cell_type":"markdown","id":"6914e404-84de-4f8b-a0ce-3232a6272d0f","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["#### Defining a schema using Data Definition Language (DDL) "]},{"cell_type":"code","execution_count":null,"id":"560ae64c-f19d-4746-b266-b344d9be3abf","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["schema_ddl = \"firstname STRING, middlename STRING, lastname STRING, id STRING, gender STRING, salary INT \" \n","df_with_ddl_schema = spark.createDataFrame(data=data2,schema=schema_ddl)\n","df.printSchema()"]}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"}},"notebook_environment":{},"nteract":{"version":"nteract-front-end@1.0.0"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{},"enableDebugMode":false}},"synapse_widget":{"state":{},"version":"0.1"},"trident":{"lakehouse":{}},"widgets":{}},"nbformat":4,"nbformat_minor":5}
