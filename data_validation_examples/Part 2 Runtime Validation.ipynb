{"cells":[{"cell_type":"markdown","source":["## Run the validation on new data/ from configuration files \n","In the last notebook, we set up the Great Expectations configuration for Data Validation in Microsoft Fabric. \n","\n","We ran it through once to generate the complete Data Context and then outputted it into the Lakehouse Files area. \n","\n","This notebook is built to be embedded within a data pipeline. \n","\n","It \n","- is built to validate bronze Lakehouse tables, and if it passes all validation checks, it will be written to a Silver table. \n","- uses a predefined Great Expectations Data Context, \n","- performs a checkpoint validation, \n","- writes the Checkpoint Results to a Lakehouse Table\n","- if it fails, it will raise and Exception, which can be handled within the Data Pipeline. \n","\n","#### Step 1: Re-initialise the Data Context from Lakehouse Files"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"ce12972b-5465-4738-8ed1-36f864ff5cb8"},{"cell_type":"code","source":["from great_expectations.data_context import FileDataContext\n","\n","path_to_local_context = '/lakehouse/default/Files'\n","\n","# initialise the data context from the Lakehouse Files\n","context = FileDataContext.create(project_root_dir=path_to_local_context)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"a4566f6f-0b43-412a-9ca4-e2be2501993a","statement_id":15,"state":"finished","livy_statement_state":"available","queued_time":"2023-08-28T14:35:07.1817119Z","session_start_time":"2023-08-28T14:35:07.4229212Z","execution_start_time":"2023-08-28T14:35:07.6229252Z","execution_finish_time":"2023-08-28T14:35:09.4364313Z","spark_jobs":{"numbers":{"SUCCEEDED":0,"FAILED":0,"UNKNOWN":0,"RUNNING":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"af5b3f7f-b811-40ce-bdcf-4da9ddc639b7"},"text/plain":"StatementMeta(, a4566f6f-0b43-412a-9ca4-e2be2501993a, 15, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["/home/trusted-service-user/cluster-env/clonedenv/lib/python3.10/site-packages/great_expectations/data_context/data_context/serializable_data_context.py:223: UserWarning: Warning. An existing `great_expectations.yml` was found here: /lakehouse/default/Files/great_expectations.\n    - No action was taken.\n  warnings.warn(message)\n\n/home/trusted-service-user/cluster-env/clonedenv/lib/python3.10/site-packages/great_expectations/data_context/data_context/serializable_data_context.py:235: UserWarning: Warning. An existing `config_variables.yml` was found here: /lakehouse/default/Files/great_expectations/uncommitted.\n    - No action was taken.\n  warnings.warn(message)\n\n"]}],"execution_count":10,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"526cda23-59dd-4ede-89bf-54eff3d24df8"},{"cell_type":"markdown","source":["#### Step 2: Get fresh dataframe and build a next batch request"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"8e54dcb4-9166-46e3-a90e-f10fc6ca5a25"},{"cell_type":"code","source":["# get a fresh load of data\n","bronze_dataframe = spark.sql(\"SELECT * FROM TutorialLakehouse.historic_weather_data LIMIT 1000\")\n","\n","# get my data asset from the data context\n","my_asset = context.get_datasource(\"my_spark_datasource\").get_asset(\"my_df_asset\")\n","\n","# create a new batch request from the new data\n","my_asset.build_batch_request(dataframe=bronze_dataframe)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"a4566f6f-0b43-412a-9ca4-e2be2501993a","statement_id":53,"state":"cancelled","livy_statement_state":"waiting","queued_time":"2023-08-28T15:14:58.2867539Z","session_start_time":null,"execution_start_time":"2023-08-28T15:14:58.6190268Z","execution_finish_time":"2023-08-28T15:15:00.9010398Z","spark_jobs":{"numbers":{"SUCCEEDED":0,"FAILED":0,"UNKNOWN":0,"RUNNING":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"ceecd20a-2ea2-4106-ad39-94331857eee4"},"text/plain":"StatementMeta(, a4566f6f-0b43-412a-9ca4-e2be2501993a, 53, Cancelled, Waiting)"},"metadata":{}}],"execution_count":46,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"f2b4f3e0-3438-455e-9e87-5569201230cd"},{"cell_type":"markdown","source":["#### Step 3: Re-run the checkpoint again, with the new context. \n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"d09d6d27-c0e8-4684-af92-a613af9b6c4e"},{"cell_type":"code","source":["results = context.run_checkpoint(checkpoint_name=\"my_checkpoint\" )"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"a4566f6f-0b43-412a-9ca4-e2be2501993a","statement_id":43,"state":"finished","livy_statement_state":"available","queued_time":"2023-08-28T15:09:21.8304247Z","session_start_time":null,"execution_start_time":"2023-08-28T15:09:22.1666288Z","execution_finish_time":"2023-08-28T15:09:30.6710139Z","spark_jobs":{"numbers":{"SUCCEEDED":6,"FAILED":0,"UNKNOWN":0,"RUNNING":0},"jobs":[{"displayName":"collect at /home/trusted-service-user/cluster-env/clonedenv/lib/python3.10/site-packages/great_expectations/execution_engine/sparkdf_execution_engine.py:765","dataWritten":0,"dataRead":1872,"rowCount":1,"usageDescription":"","jobId":29,"name":"collect at /home/trusted-service-user/cluster-env/clonedenv/lib/python3.10/site-packages/great_expectations/execution_engine/sparkdf_execution_engine.py:765","description":"Job group for statement 43:\nresults = context.run_checkpoint(checkpoint_name=\"my_checkpoint\" )","submissionTime":"2023-08-28T15:09:23.054GMT","completionTime":"2023-08-28T15:09:23.086GMT","stageIds":[54,55],"jobGroup":"43","status":"SUCCEEDED","numTasks":9,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":8,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /home/trusted-service-user/cluster-env/clonedenv/lib/python3.10/site-packages/great_expectations/expectations/metrics/map_metric_provider/column_map_condition_auxilliary_methods.py:388","dataWritten":0,"dataRead":1872,"rowCount":1,"usageDescription":"","jobId":28,"name":"collect at /home/trusted-service-user/cluster-env/clonedenv/lib/python3.10/site-packages/great_expectations/expectations/metrics/map_metric_provider/column_map_condition_auxilliary_methods.py:388","description":"Job group for statement 43:\nresults = context.run_checkpoint(checkpoint_name=\"my_checkpoint\" )","submissionTime":"2023-08-28T15:09:22.972GMT","completionTime":"2023-08-28T15:09:22.989GMT","stageIds":[52,53],"jobGroup":"43","status":"SUCCEEDED","numTasks":9,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":8,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /home/trusted-service-user/cluster-env/clonedenv/lib/python3.10/site-packages/great_expectations/expectations/metrics/map_metric_provider/column_map_condition_auxilliary_methods.py:388","dataWritten":0,"dataRead":1872,"rowCount":1,"usageDescription":"","jobId":27,"name":"collect at /home/trusted-service-user/cluster-env/clonedenv/lib/python3.10/site-packages/great_expectations/expectations/metrics/map_metric_provider/column_map_condition_auxilliary_methods.py:388","description":"Job group for statement 43:\nresults = context.run_checkpoint(checkpoint_name=\"my_checkpoint\" )","submissionTime":"2023-08-28T15:09:22.914GMT","completionTime":"2023-08-28T15:09:22.930GMT","stageIds":[51,50],"jobGroup":"43","status":"SUCCEEDED","numTasks":9,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":8,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /home/trusted-service-user/cluster-env/clonedenv/lib/python3.10/site-packages/great_expectations/expectations/metrics/map_metric_provider/column_map_condition_auxilliary_methods.py:388","dataWritten":0,"dataRead":1872,"rowCount":1,"usageDescription":"","jobId":26,"name":"collect at /home/trusted-service-user/cluster-env/clonedenv/lib/python3.10/site-packages/great_expectations/expectations/metrics/map_metric_provider/column_map_condition_auxilliary_methods.py:388","description":"Job group for statement 43:\nresults = context.run_checkpoint(checkpoint_name=\"my_checkpoint\" )","submissionTime":"2023-08-28T15:09:22.850GMT","completionTime":"2023-08-28T15:09:22.870GMT","stageIds":[48,49],"jobGroup":"43","status":"SUCCEEDED","numTasks":9,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":8,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /home/trusted-service-user/cluster-env/clonedenv/lib/python3.10/site-packages/great_expectations/expectations/metrics/map_metric_provider/column_map_condition_auxilliary_methods.py:388","dataWritten":0,"dataRead":1872,"rowCount":1,"usageDescription":"","jobId":25,"name":"collect at /home/trusted-service-user/cluster-env/clonedenv/lib/python3.10/site-packages/great_expectations/expectations/metrics/map_metric_provider/column_map_condition_auxilliary_methods.py:388","description":"Job group for statement 43:\nresults = context.run_checkpoint(checkpoint_name=\"my_checkpoint\" )","submissionTime":"2023-08-28T15:09:22.798GMT","completionTime":"2023-08-28T15:09:22.814GMT","stageIds":[46,47],"jobGroup":"43","status":"SUCCEEDED","numTasks":9,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":8,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /home/trusted-service-user/cluster-env/clonedenv/lib/python3.10/site-packages/great_expectations/execution_engine/sparkdf_execution_engine.py:765","dataWritten":0,"dataRead":1872,"rowCount":1,"usageDescription":"","jobId":24,"name":"collect at /home/trusted-service-user/cluster-env/clonedenv/lib/python3.10/site-packages/great_expectations/execution_engine/sparkdf_execution_engine.py:765","description":"Job group for statement 43:\nresults = context.run_checkpoint(checkpoint_name=\"my_checkpoint\" )","submissionTime":"2023-08-28T15:09:22.692GMT","completionTime":"2023-08-28T15:09:22.712GMT","stageIds":[45,44],"jobGroup":"43","status":"SUCCEEDED","numTasks":9,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":8,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"6bf714a1-d5ef-4094-ac90-f77d093356dd"},"text/plain":"StatementMeta(, a4566f6f-0b43-412a-9ca4-e2be2501993a, 43, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["/home/trusted-service-user/cluster-env/clonedenv/lib/python3.10/site-packages/ipykernel/comm/comm.py:79: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  warn(\n\n"]},{"output_type":"display_data","data":{"text/plain":"Calculating Metrics:   0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c6243b5d7424df4b1fc93b86243c4b8"}},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"a4566f6f-0b43-412a-9ca4-e2be2501993a","statement_id":44,"state":"finished","livy_statement_state":"available","queued_time":"2023-08-28T15:09:25.4725169Z","session_start_time":null,"execution_start_time":"2023-08-28T15:09:31.0723631Z","execution_finish_time":"2023-08-28T15:09:31.4075528Z","spark_jobs":{"numbers":{"SUCCEEDED":0,"FAILED":0,"UNKNOWN":0,"RUNNING":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"7eacc094-c416-4629-95be-909cf0cb0176"},"text/plain":"StatementMeta(, a4566f6f-0b43-412a-9ca4-e2be2501993a, 44, Finished, Available)"},"metadata":{}}],"execution_count":37,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"cf03d4ec-a4b6-44b5-8421-0e039d398fec"},{"cell_type":"markdown","source":["#### Step 4: Handle results\n","Now we have some results, we want to perform some actions: \n","- log the results in a validation log Lakehouse table\n","- if success, write to Silver Table\n","- if failure, throw an exception to be handled by data pipeline "],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"318b510e-5c66-4e15-8c45-2c05155e40ae"},{"cell_type":"code","source":["import pandas as pd\n","from datetime import datetime \n","\n","def load_to_silver(validated_bronze): \n","    validated_bronze.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/silver_historic_weather_data\")\n","\n","\n","\n","def parse_and_load_checkpoint_result(results): \n","\n","    validation_results = results['run_results'][next(iter(results['run_results']))]['validation_result']\n","    success = validation_results['success']\n","    \n","    restructured = {\n","        \"run_name\": [results['run_id']['run_name']], \n","        \"run_time\": [datetime.strptime(results['run_id']['run_time'][:19], \"%Y-%m-%dT%H:%M:%S\")],\n","        \"validation_result\": [success], \n","        \"evaluated_expectations\": [validation_results['statistics']['evaluated_expectations']],\n","        \"successful_expectations\": [validation_results['statistics']['successful_expectations']],\n","        \"unsuccessful_expectations\": [validation_results['statistics']['unsuccessful_expectations']],\n","        \"success_percent\": [validation_results['statistics']['success_percent']],\n","        \"expectation_suite_name\": [validation_results['meta']['expectation_suite_name']]\n","    }\n","\n","    pandas_df = pd.DataFrame(restructured)\n","    spark_df = spark.createDataFrame(pandas_df)\n","    spark_df.write.format(\"delta\").mode(\"append\").save(\"Tables/validation_results\")\n","\n","    return success\n","    \n","success = parse_and_load_checkpoint_result(results.to_json_dict())\n","\n","if success: \n","    load_to_silver(bronze_dataframe)\n","else: \n","    raise Exception(\"Handle the exception in the data pipeline.\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"a4566f6f-0b43-412a-9ca4-e2be2501993a","statement_id":60,"state":"finished","livy_statement_state":"available","queued_time":"2023-08-28T15:34:55.2219764Z","session_start_time":null,"execution_start_time":"2023-08-28T15:34:55.5640084Z","execution_finish_time":"2023-08-28T15:35:00.4720726Z","spark_jobs":{"numbers":{"SUCCEEDED":11,"FAILED":0,"UNKNOWN":0,"RUNNING":0},"jobs":[{"displayName":"toString at String.java:2994","dataWritten":0,"dataRead":4400,"rowCount":50,"usageDescription":"","jobId":50,"name":"toString at String.java:2994","description":"Delta: Job group for statement 60:\nimport pandas as pd\nfrom datetime import datetime \n\ndef load_to_silver(validated_bronze): \n    validated_bronze.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/silver_historic_weather_data\")\n\n\n\ndef parse_and_load_checkpoint_result(results): \n\n    validation_results = results['run_results'][next(iter(results['run_results']))]['validation_result']\n    success = validation_results['success']\n    \n    restructured = {\n        \"run_name\": [results['run_id']['run_name']], \n        \"run_time\": [datetime.strptime(results['run_id']['run_time'][:19], \"%Y-%m-%dT%H:%M:%S\")],\n        \"validation_result\": [success], \n        \"evaluated_expectations\": [validation_results['statistics']['evaluated_expectations']],\n        \"successful_expectations\": [validation_results['statistics']['successful_expectations']],\n        \"unsuccessful_expectations\": [validation_results['statistics']['unsuccessful_expectations']],\n        \"success_percent\": [validation_results['statistics']['success_percent']],\n        \"expectation_suite_nam...: Compute snapshot for version: 0","submissionTime":"2023-08-28T15:34:59.315GMT","completionTime":"2023-08-28T15:34:59.357GMT","stageIds":[93,91,92],"jobGroup":"60","status":"SUCCEEDED","numTasks":52,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":51,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":2,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":4400,"dataRead":1754,"rowCount":54,"usageDescription":"","jobId":49,"name":"toString at String.java:2994","description":"Delta: Job group for statement 60:\nimport pandas as pd\nfrom datetime import datetime \n\ndef load_to_silver(validated_bronze): \n    validated_bronze.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/silver_historic_weather_data\")\n\n\n\ndef parse_and_load_checkpoint_result(results): \n\n    validation_results = results['run_results'][next(iter(results['run_results']))]['validation_result']\n    success = validation_results['success']\n    \n    restructured = {\n        \"run_name\": [results['run_id']['run_name']], \n        \"run_time\": [datetime.strptime(results['run_id']['run_time'][:19], \"%Y-%m-%dT%H:%M:%S\")],\n        \"validation_result\": [success], \n        \"evaluated_expectations\": [validation_results['statistics']['evaluated_expectations']],\n        \"successful_expectations\": [validation_results['statistics']['successful_expectations']],\n        \"unsuccessful_expectations\": [validation_results['statistics']['unsuccessful_expectations']],\n        \"success_percent\": [validation_results['statistics']['success_percent']],\n        \"expectation_suite_nam...: Compute snapshot for version: 0","submissionTime":"2023-08-28T15:34:58.678GMT","completionTime":"2023-08-28T15:34:59.292GMT","stageIds":[89,90],"jobGroup":"60","status":"SUCCEEDED","numTasks":51,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":1,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":1754,"dataRead":1975,"rowCount":8,"usageDescription":"","jobId":48,"name":"toString at String.java:2994","description":"Delta: Job group for statement 60:\nimport pandas as pd\nfrom datetime import datetime \n\ndef load_to_silver(validated_bronze): \n    validated_bronze.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/silver_historic_weather_data\")\n\n\n\ndef parse_and_load_checkpoint_result(results): \n\n    validation_results = results['run_results'][next(iter(results['run_results']))]['validation_result']\n    success = validation_results['success']\n    \n    restructured = {\n        \"run_name\": [results['run_id']['run_name']], \n        \"run_time\": [datetime.strptime(results['run_id']['run_time'][:19], \"%Y-%m-%dT%H:%M:%S\")],\n        \"validation_result\": [success], \n        \"evaluated_expectations\": [validation_results['statistics']['evaluated_expectations']],\n        \"successful_expectations\": [validation_results['statistics']['successful_expectations']],\n        \"unsuccessful_expectations\": [validation_results['statistics']['unsuccessful_expectations']],\n        \"success_percent\": [validation_results['statistics']['success_percent']],\n        \"expectation_suite_nam...: Compute snapshot for version: 0","submissionTime":"2023-08-28T15:34:58.501GMT","completionTime":"2023-08-28T15:34:58.549GMT","stageIds":[88],"jobGroup":"60","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"Job group for statement 60:\nimport pandas as pd\nfrom datetime import datetime \n\ndef load_to_silver(validated_bronze): \n    validated_bronze.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/silver_historic_weather_data\")\n\n\n\ndef parse_and_load_checkpoint_result(results): \n\n    validation_results = results['run_results'][next(iter(results['run_results']))]['validation_result']\n    success = validation_results['success']\n    \n    restructured = {\n        \"run_name\": [results['run_id']['run_name']], \n        \"run_time\": [datetime.strptime(results['run_id']['run_time'][:19], \"%Y-%m-%dT%H:%M:%S\")],\n        \"validation_result\": [success], \n        \"evaluated_expectations\": [validation_results['statistics']['evaluated_expectations']],\n        \"successful_expectations\": [validation_results['statistics']['successful_expectations']],\n        \"unsuccessful_expectations\": [validation_results['statistics']['unsuccessful_expectations']],\n        \"success_percent\": [validation_results['statistics']['success_percent']],\n        \"expectation_suite_nam...","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":47,"name":"","description":"Job group for statement 60:\nimport pandas as pd\nfrom datetime import datetime \n\ndef load_to_silver(validated_bronze): \n    validated_bronze.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/silver_historic_weather_data\")\n\n\n\ndef parse_and_load_checkpoint_result(results): \n\n    validation_results = results['run_results'][next(iter(results['run_results']))]['validation_result']\n    success = validation_results['success']\n    \n    restructured = {\n        \"run_name\": [results['run_id']['run_name']], \n        \"run_time\": [datetime.strptime(results['run_id']['run_time'][:19], \"%Y-%m-%dT%H:%M:%S\")],\n        \"validation_result\": [success], \n        \"evaluated_expectations\": [validation_results['statistics']['evaluated_expectations']],\n        \"successful_expectations\": [validation_results['statistics']['successful_expectations']],\n        \"unsuccessful_expectations\": [validation_results['statistics']['unsuccessful_expectations']],\n        \"success_percent\": [validation_results['statistics']['success_percent']],\n        \"expectation_suite_nam...","submissionTime":"2023-08-28T15:34:58.024GMT","completionTime":"2023-08-28T15:34:58.024GMT","stageIds":[],"jobGroup":"60","status":"SUCCEEDED","numTasks":0,"numActiveTasks":0,"numCompletedTasks":0,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":0,"numActiveStages":0,"numCompletedStages":0,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":3227,"dataRead":569,"rowCount":32,"usageDescription":"","jobId":46,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 60:\nimport pandas as pd\nfrom datetime import datetime \n\ndef load_to_silver(validated_bronze): \n    validated_bronze.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/silver_historic_weather_data\")\n\n\n\ndef parse_and_load_checkpoint_result(results): \n\n    validation_results = results['run_results'][next(iter(results['run_results']))]['validation_result']\n    success = validation_results['success']\n    \n    restructured = {\n        \"run_name\": [results['run_id']['run_name']], \n        \"run_time\": [datetime.strptime(results['run_id']['run_time'][:19], \"%Y-%m-%dT%H:%M:%S\")],\n        \"validation_result\": [success], \n        \"evaluated_expectations\": [validation_results['statistics']['evaluated_expectations']],\n        \"successful_expectations\": [validation_results['statistics']['successful_expectations']],\n        \"unsuccessful_expectations\": [validation_results['statistics']['unsuccessful_expectations']],\n        \"success_percent\": [validation_results['statistics']['success_percent']],\n        \"expectation_suite_nam...","submissionTime":"2023-08-28T15:34:57.529GMT","completionTime":"2023-08-28T15:34:57.887GMT","stageIds":[85,86,87],"jobGroup":"60","status":"SUCCEEDED","numTasks":10,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":9,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":2,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":569,"dataRead":1872,"rowCount":17,"usageDescription":"","jobId":45,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 60:\nimport pandas as pd\nfrom datetime import datetime \n\ndef load_to_silver(validated_bronze): \n    validated_bronze.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/silver_historic_weather_data\")\n\n\n\ndef parse_and_load_checkpoint_result(results): \n\n    validation_results = results['run_results'][next(iter(results['run_results']))]['validation_result']\n    success = validation_results['success']\n    \n    restructured = {\n        \"run_name\": [results['run_id']['run_name']], \n        \"run_time\": [datetime.strptime(results['run_id']['run_time'][:19], \"%Y-%m-%dT%H:%M:%S\")],\n        \"validation_result\": [success], \n        \"evaluated_expectations\": [validation_results['statistics']['evaluated_expectations']],\n        \"successful_expectations\": [validation_results['statistics']['successful_expectations']],\n        \"unsuccessful_expectations\": [validation_results['statistics']['unsuccessful_expectations']],\n        \"success_percent\": [validation_results['statistics']['success_percent']],\n        \"expectation_suite_nam...","submissionTime":"2023-08-28T15:34:57.457GMT","completionTime":"2023-08-28T15:34:57.489GMT","stageIds":[84,83],"jobGroup":"60","status":"SUCCEEDED","numTasks":9,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":8,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":0,"dataRead":4453,"rowCount":50,"usageDescription":"","jobId":44,"name":"toString at String.java:2994","description":"Delta: Job group for statement 60:\nimport pandas as pd\nfrom datetime import datetime \n\ndef load_to_silver(validated_bronze): \n    validated_bronze.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/silver_historic_weather_data\")\n\n\n\ndef parse_and_load_checkpoint_result(results): \n\n    validation_results = results['run_results'][next(iter(results['run_results']))]['validation_result']\n    success = validation_results['success']\n    \n    restructured = {\n        \"run_name\": [results['run_id']['run_name']], \n        \"run_time\": [datetime.strptime(results['run_id']['run_time'][:19], \"%Y-%m-%dT%H:%M:%S\")],\n        \"validation_result\": [success], \n        \"evaluated_expectations\": [validation_results['statistics']['evaluated_expectations']],\n        \"successful_expectations\": [validation_results['statistics']['successful_expectations']],\n        \"unsuccessful_expectations\": [validation_results['statistics']['unsuccessful_expectations']],\n        \"success_percent\": [validation_results['statistics']['success_percent']],\n        \"expectation_suite_nam...: Compute snapshot for version: 2","submissionTime":"2023-08-28T15:34:57.213GMT","completionTime":"2023-08-28T15:34:57.243GMT","stageIds":[81,82,80],"jobGroup":"60","status":"SUCCEEDED","numTasks":54,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":53,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":2,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":4453,"dataRead":4147,"rowCount":58,"usageDescription":"","jobId":43,"name":"toString at String.java:2994","description":"Delta: Job group for statement 60:\nimport pandas as pd\nfrom datetime import datetime \n\ndef load_to_silver(validated_bronze): \n    validated_bronze.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/silver_historic_weather_data\")\n\n\n\ndef parse_and_load_checkpoint_result(results): \n\n    validation_results = results['run_results'][next(iter(results['run_results']))]['validation_result']\n    success = validation_results['success']\n    \n    restructured = {\n        \"run_name\": [results['run_id']['run_name']], \n        \"run_time\": [datetime.strptime(results['run_id']['run_time'][:19], \"%Y-%m-%dT%H:%M:%S\")],\n        \"validation_result\": [success], \n        \"evaluated_expectations\": [validation_results['statistics']['evaluated_expectations']],\n        \"successful_expectations\": [validation_results['statistics']['successful_expectations']],\n        \"unsuccessful_expectations\": [validation_results['statistics']['unsuccessful_expectations']],\n        \"success_percent\": [validation_results['statistics']['success_percent']],\n        \"expectation_suite_nam...: Compute snapshot for version: 2","submissionTime":"2023-08-28T15:34:56.566GMT","completionTime":"2023-08-28T15:34:57.195GMT","stageIds":[78,79],"jobGroup":"60","status":"SUCCEEDED","numTasks":53,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":3,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":4147,"dataRead":5173,"rowCount":16,"usageDescription":"","jobId":42,"name":"toString at String.java:2994","description":"Delta: Job group for statement 60:\nimport pandas as pd\nfrom datetime import datetime \n\ndef load_to_silver(validated_bronze): \n    validated_bronze.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/silver_historic_weather_data\")\n\n\n\ndef parse_and_load_checkpoint_result(results): \n\n    validation_results = results['run_results'][next(iter(results['run_results']))]['validation_result']\n    success = validation_results['success']\n    \n    restructured = {\n        \"run_name\": [results['run_id']['run_name']], \n        \"run_time\": [datetime.strptime(results['run_id']['run_time'][:19], \"%Y-%m-%dT%H:%M:%S\")],\n        \"validation_result\": [success], \n        \"evaluated_expectations\": [validation_results['statistics']['evaluated_expectations']],\n        \"successful_expectations\": [validation_results['statistics']['successful_expectations']],\n        \"unsuccessful_expectations\": [validation_results['statistics']['unsuccessful_expectations']],\n        \"success_percent\": [validation_results['statistics']['success_percent']],\n        \"expectation_suite_nam...: Compute snapshot for version: 2","submissionTime":"2023-08-28T15:34:56.368GMT","completionTime":"2023-08-28T15:34:56.436GMT","stageIds":[77],"jobGroup":"60","status":"SUCCEEDED","numTasks":3,"numActiveTasks":0,"numCompletedTasks":3,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":3,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":4140,"dataRead":154,"rowCount":2,"usageDescription":"","jobId":41,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 60:\nimport pandas as pd\nfrom datetime import datetime \n\ndef load_to_silver(validated_bronze): \n    validated_bronze.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/silver_historic_weather_data\")\n\n\n\ndef parse_and_load_checkpoint_result(results): \n\n    validation_results = results['run_results'][next(iter(results['run_results']))]['validation_result']\n    success = validation_results['success']\n    \n    restructured = {\n        \"run_name\": [results['run_id']['run_name']], \n        \"run_time\": [datetime.strptime(results['run_id']['run_time'][:19], \"%Y-%m-%dT%H:%M:%S\")],\n        \"validation_result\": [success], \n        \"evaluated_expectations\": [validation_results['statistics']['evaluated_expectations']],\n        \"successful_expectations\": [validation_results['statistics']['successful_expectations']],\n        \"unsuccessful_expectations\": [validation_results['statistics']['unsuccessful_expectations']],\n        \"success_percent\": [validation_results['statistics']['success_percent']],\n        \"expectation_suite_nam...","submissionTime":"2023-08-28T15:34:55.677GMT","completionTime":"2023-08-28T15:34:55.915GMT","stageIds":[75,76],"jobGroup":"60","status":"SUCCEEDED","numTasks":2,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":1,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":154,"dataRead":0,"rowCount":1,"usageDescription":"","jobId":40,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 60:\nimport pandas as pd\nfrom datetime import datetime \n\ndef load_to_silver(validated_bronze): \n    validated_bronze.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/silver_historic_weather_data\")\n\n\n\ndef parse_and_load_checkpoint_result(results): \n\n    validation_results = results['run_results'][next(iter(results['run_results']))]['validation_result']\n    success = validation_results['success']\n    \n    restructured = {\n        \"run_name\": [results['run_id']['run_name']], \n        \"run_time\": [datetime.strptime(results['run_id']['run_time'][:19], \"%Y-%m-%dT%H:%M:%S\")],\n        \"validation_result\": [success], \n        \"evaluated_expectations\": [validation_results['statistics']['evaluated_expectations']],\n        \"successful_expectations\": [validation_results['statistics']['successful_expectations']],\n        \"unsuccessful_expectations\": [validation_results['statistics']['unsuccessful_expectations']],\n        \"success_percent\": [validation_results['statistics']['success_percent']],\n        \"expectation_suite_nam...","submissionTime":"2023-08-28T15:34:55.616GMT","completionTime":"2023-08-28T15:34:55.630GMT","stageIds":[74],"jobGroup":"60","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"886a1307-cbce-480e-8ec0-0c2f30850e10"},"text/plain":"StatementMeta(, a4566f6f-0b43-412a-9ca4-e2be2501993a, 60, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["/opt/spark/python/lib/pyspark.zip/pyspark/sql/pandas/utils.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n\n/opt/spark/python/lib/pyspark.zip/pyspark/sql/pandas/utils.py:64: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n\n/opt/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:604: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n\n"]}],"execution_count":53,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"992d8904-dc15-422a-8caa-5d6b8c508c28"}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"},"host":{"trident":{"lakehouse":{"known_lakehouses":"[{\"id\":\"e1916538-6a3d-460f-8fc3-7015ac00156c\"}]","default_lakehouse":"e1916538-6a3d-460f-8fc3-7015ac00156c"}},"synapse_widget":{"token":"10a67b6b-d3fd-4826-b2a8-f31de0fe20df","state":{}}}},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"widgets":{},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{}}},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{}},"trident":{"lakehouse":{"default_lakehouse":"e1916538-6a3d-460f-8fc3-7015ac00156c","known_lakehouses":[{"id":"e1916538-6a3d-460f-8fc3-7015ac00156c"}],"default_lakehouse_name":"TutorialLakehouse","default_lakehouse_workspace_id":"aa704a83-c7ad-4659-8e45-afc263404203"}}},"nbformat":4,"nbformat_minor":5}